<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Deep and Structured - L2 Notes(下) | NaiveRed&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Neural Network (Basic Ideas)">
<meta name="keywords" content="Machine Learning,Deep Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Deep and Structured - L2 Notes(下)">
<meta property="og:url" content="http://naivered.github.io/2016/10/01/Study_Notes/Machine Learning/Deep-and-Structured-L2-Notes-2/index.html">
<meta property="og:site_name" content="NaiveRed&#39;s Blog">
<meta property="og:description" content="Neural Network (Basic Ideas)">
<meta property="og:image" content="http://imgur.com/39hyEvv.jpg">
<meta property="og:image" content="http://imgur.com/YALMlDw.jpg">
<meta property="og:image" content="http://imgur.com/zoEtjQI.jpg">
<meta property="og:image" content="http://imgur.com/fDqECi5.jpg">
<meta property="og:image" content="http://imgur.com/0vLZTKG.jpg">
<meta property="og:image" content="http://imgur.com/w8RbX1m.jpg">
<meta property="og:image" content="http://imgur.com/9mcTgWe.jpg">
<meta property="og:image" content="http://imgur.com/7KhIydM.jpg">
<meta property="og:image" content="http://imgur.com/5UfbHyM.jpg">
<meta property="og:image" content="http://imgur.com/TsMXQz5.jpg">
<meta property="og:image" content="http://imgur.com/hJCU5Yx.jpg">
<meta property="og:image" content="http://imgur.com/YdKkg8P.jpg">
<meta property="og:image" content="http://imgur.com/cPbpaiz.jpg">
<meta property="og:image" content="http://imgur.com/T7bFt1b.jpg">
<meta property="og:image" content="http://imgur.com/cZkL72s.jpg">
<meta property="og:image" content="http://imgur.com/TrD29wC.jpg">
<meta property="og:image" content="http://imgur.com/jyqTtWV.jpg">
<meta property="og:image" content="http://imgur.com/9cQj3lN.jpg">
<meta property="og:image" content="http://imgur.com/qpaMsoD.jpg">
<meta property="og:image" content="http://imgur.com/K75m9j4.jpg">
<meta property="og:updated_time" content="2017-01-17T08:18:50.921Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Deep and Structured - L2 Notes(下)">
<meta name="twitter:description" content="Neural Network (Basic Ideas)">
<meta name="twitter:image" content="http://imgur.com/39hyEvv.jpg">
  
    <link rel="alternate" href="/atom.xml" title="NaiveRed&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-73951673-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">NaiveRed&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Don&#39;t Panic!</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/tags">Tags</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://naivered.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Study_Notes/Machine Learning/Deep-and-Structured-L2-Notes-2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/10/01/Study_Notes/Machine Learning/Deep-and-Structured-L2-Notes-2/" class="article-date">
  <time datetime="2016-10-01T05:40:01.000Z" itemprop="datePublished">2016-10-01</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/學習筆記/">學習筆記</a>►<a class="article-category-link" href="/categories/學習筆記/ML-Hung-yi-Lee/">ML(Hung-yi Lee)</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Deep and Structured - L2 Notes(下)
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
          
            <div id="toc" class="toc-article">
            <h2 class="toc-title">Contents</h2>
			  
                <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Neural-Network-Basic-Ideas"><span class="toc-number">1.</span> <span class="toc-text">Neural Network (Basic Ideas)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#How-to-pick-the-“Best”-function"><span class="toc-number">1.1.</span> <span class="toc-text">How to pick the “Best” function</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Gradient-Descent"><span class="toc-number">1.1.1.</span> <span class="toc-text">Gradient Descent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Gradient-Descent-的原理"><span class="toc-number">1.1.2.</span> <span class="toc-text">Gradient Descent 的原理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Practical-Issues"><span class="toc-number">1.2.</span> <span class="toc-text">Practical Issues</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Learning-Rate"><span class="toc-number">1.2.1.</span> <span class="toc-text">Learning Rate</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Stochastic-Gradient-Descent"><span class="toc-number">1.2.2.</span> <span class="toc-text">Stochastic Gradient Descent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Mini-batch-Gradient-Descent"><span class="toc-number">1.2.3.</span> <span class="toc-text">Mini-batch Gradient Descent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Recipe-for-Learning"><span class="toc-number">1.2.4.</span> <span class="toc-text">Recipe for Learning</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#總結"><span class="toc-number">1.3.</span> <span class="toc-text">總結</span></a></li></ol></li></ol> 
              
            </div>
        
        <h1 id="Neural-Network-Basic-Ideas"><a href="#Neural-Network-Basic-Ideas" class="headerlink" title="Neural Network (Basic Ideas)"></a>Neural Network (Basic Ideas)</h1><a id="more"></a>
<h2 id="How-to-pick-the-“Best”-function"><a href="#How-to-pick-the-“Best”-function" class="headerlink" title="How to pick the “Best” function"></a>How to pick the “Best” function</h2><p>現在的問題點是要如何找到一組 parameter 來讓 $C(\theta)$ 最小。這邊採用的方法是 <strong>Gradient Descent</strong> 。</p>
<h3 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h3><p>先簡化一下 parameter ，變成只有一個變數。其想法就是，對某點作 <strong>微分</strong> 後得到其斜率，再依據斜率決定要如何 <strong>移動</strong> 點。  </p>
<p>如果斜率為負: 將點往右移<br>如果斜率為正: 將點往左移</p>
<p>$\theta^0$ 要加上  斜率乘 $- \eta$  。如果斜率為負，要往右移，所以要加負號。反之則是往左。(斜率取絕對值後，值越大代表直線越陡峭)<br>至於 $\eta$ 則是指 <strong>learning rate</strong>。(移動的距離有多寬)</p>
<p>目的是要找一個點使的 $C(\theta)$ 為 <strong>local minimum</strong>。</p>
<p><img src="http://imgur.com/39hyEvv.jpg" alt="2-44"></p>
<p>接著來看如果一組 parameter 內有 <strong>兩個變數</strong> 的話:  </p>
<p>$\theta$ 的 上標 代表第幾組 parameter，下標(1,2) 則是變數(兩個)。  </p>
<p>其 <strong>梯度($\nabla$)</strong> 對兩個變數去做 <strong>偏微分</strong>，算出來的結果一樣是 2 維的 vector。<br>接著就是去找下一個點 =&gt; <strong>Update Parameter</strong> ，寫成式子如下圖:</p>
<p><img src="http://imgur.com/YALMlDw.jpg" alt="2-45"></p>
<p>用圖來表示這一連串的操作就會是這樣:  </p>
<p>loop: 計算 <strong>Gradient $\nabla$</strong> -&gt; 移動點  </p>
<p>直到 Gradient 的 <strong>norm</strong>($\nabla C(\theta)$) 算出來接近零才停。</p>
<p><img src="http://imgur.com/zoEtjQI.jpg" alt="2-46"></p>
<p>關於倒三角這個符號，<a href="https://zh.wikipedia.org/wiki/Nabla%E7%AE%97%E5%AD%90" target="_blank" rel="noopener">向量微分算子</a>。</p>
<h3 id="Gradient-Descent-的原理"><a href="#Gradient-Descent-的原理" class="headerlink" title="Gradient Descent 的原理"></a>Gradient Descent 的原理</h3><p>同樣是以兩個變數為例，在下圖中線上的數字代表著 $C(\theta)$ 的值，而圖中的點就是每次 update 的 parameter。  </p>
<p>而我們可以做到的事是: 給我一個點，可以知道這個點 <strong>附近</strong> 的 $C(\theta)$ <strong>最小值</strong> 是在哪一點。<br>所以我們就一直往這個會使 $C(\theta)$ 變小的地方邁進，最後就會走到 <strong>local minimum</strong>。<br>這邊所謂的 附近 ，就如同圖中的紅圈一樣。有個有趣的比喻: 就像是 <strong>戰爭迷霧</strong>，我們只能看到自己視野內的東西。  </p>
<p><img src="http://imgur.com/fDqECi5.jpg" alt="2-47"></p>
<p>至於怎麼看視野內的東西呢？這邊提到了 <strong>Taylor Series</strong> ，大致上就是當 $x = x_0$ ，且可微無限多次時，這個函數可以寫成圖中的 $h(x)$ 。(<a href="https://zh.wikipedia.org/wiki/%E6%B3%B0%E5%8B%92%E7%BA%A7%E6%95%B0" target="_blank" rel="noopener">Taylor Series</a>)  </p>
<p>然後當 $x_0$ 和 $x$ 很接近時， $(x-x_0)^k$ 的項後面會越來越小，所以我們可以只看它的前兩項。</p>
<p><img src="http://imgur.com/0vLZTKG.jpg" alt="2-48"></p>
<p>拓展到兩個變數:</p>
<p><img src="http://imgur.com/w8RbX1m.jpg" alt="2-50"></p>
<p>而根據 Taylor Series ，當我們有一點 $(a,b)$ 時，如果 <strong>紅色圈圈</strong> 的範圍很小(也就是跟 $(a,b)$ 很接近)，那在這範圍內的 <span>$\theta = \{ \theta_1,\theta_2 \}$</span><!-- Has MathJax --> ，其 $C(\theta)$ 可以寫成圖中那樣:   </p>
<p>更進一步來說，對於 <strong>偏微分</strong> 的那兩項，當 $C(\theta)$ 偏微分完後再帶入 $(a,b)$ ，它們也就只是個 <strong>常數</strong>( $u$ 和 $v$ ) 了，所以可以再進一步的簡化。<br>($s$ 裡漏打 $a$)</p>
<p><img src="http://imgur.com/9mcTgWe.jpg" alt="2-51"></p>
<p>有了這個式子後，我們可以輕易地找到，使這個紅圈範圍內 $C(\theta)$ 值最小的 $(\theta_1,\theta_2)$ 。<br>(至於如何求出 $\theta_1,\theta_2$ ，影片中是說自己設個範圍，然後找)<br>而最後解出來的式子如下圖:</p>
<p><img src="http://imgur.com/7KhIydM.jpg" alt="2-52"></p>
<p>可以看到圖中 $(u,v)$ 向量其實就是前面所講的 <strong>$\nabla C(a,b)$</strong>。  </p>
<p>而 <strong>learning rate</strong> 就是這個 <strong>紅色圈圈</strong> 的半徑，也就是為甚麼會有前面所說 <strong>戰爭迷霧</strong> 的問題了，因為如果 $\eta$ 設 <strong>太大</strong>，這個式子就不成立了。(在 Taylor Series 中二次項的部分也不能被刪除)<br>反過來說，如果 $\eta$ 無窮小，順著 gradient 的方向，我們就一定能讓 Cost 變小。</p>
<p>而這也帶出一件事，如果我們把 Taylor Series 中的二次項加進訓練的過程，通常可以提升訓練的效果，但也會增加額外的運算量。</p>
<h2 id="Practical-Issues"><a href="#Practical-Issues" class="headerlink" title="Practical Issues"></a>Practical Issues</h2><h3 id="Learning-Rate"><a href="#Learning-Rate" class="headerlink" title="Learning Rate"></a>Learning Rate</h3><p>對於如何設定 learning rate ，以後會在深談。這邊只先講講它的影響:<br>當太大時，有可能找不到我們要的，會發生來回震盪或直接飛出去的狀況。<br>當很小時，只要花的時間夠久都可以找到。(非常久~~)</p>
<p><img src="http://imgur.com/5UfbHyM.jpg" alt="2-58"></p>
<p><img src="http://imgur.com/TsMXQz5.jpg" alt="2-61"></p>
<h3 id="Stochastic-Gradient-Descent"><a href="#Stochastic-Gradient-Descent" class="headerlink" title="Stochastic Gradient Descent"></a>Stochastic Gradient Descent</h3><p>先來簡化一下，原先在 cost function 內，需要用每一筆資料和 $\hat{y}^r$ 做計算，這邊把每一筆簡化成 $C^r(\theta)$</p>
<p>對於前面所提的 gradient descent ，在每次 update 時需要對全部的資料都算一次，再做 sum。(實際上這樣不太行)  </p>
<p>這邊要提的叫做 <strong>Stochastic Gradient Descent</strong> :<br>每次 update 時 ，我們只 <strong>挑一筆</strong> 資料來看 $x^r$。  </p>
<p>只要 update 得夠多次，期望值算出來其實是一樣的，那這樣的好處是什麼？</p>
<p><img src="http://imgur.com/hJCU5Yx.jpg" alt="2-62"></p>
<p>要先解釋一個名詞 <strong>epoch</strong> : 把所有的 examples 都看過一次後叫 epoch。  </p>
<p><img src="http://imgur.com/YdKkg8P.jpg" alt="2-63"></p>
<p>接著來看看好處。<br>從下方這張圖可以看出，如果有 20 個 example ，原先的 Gradient Descent 要看完全部才會更新，此時 <strong>Stochastic Gradient Descent</strong> 就已經更新 20 次了。</p>
<p><img src="http://imgur.com/cPbpaiz.jpg" alt="2-64"></p>
<h3 id="Mini-batch-Gradient-Descent"><a href="#Mini-batch-Gradient-Descent" class="headerlink" title="Mini-batch Gradient Descent"></a>Mini-batch Gradient Descent</h3><p>實作上還有另一個方法，介於 Stochastic Gradient Descent 和 Gradient Descent 之間的就叫 <strong>Mini-batch Gradient Descent</strong> 。</p>
<p>做法是，每次挑選 <strong>B</strong> 個 example 來計算，B 就是 batch 的大小。 (Stochastic Gradient Descent 其實也就是 $B = 1$ 的情況)</p>
<p>要注意的地方是要 shuffle data ，因為我們希望所選出來的資料是有各式各樣類型的。</p>
<p><img src="http://imgur.com/T7bFt1b.jpg" alt="2-65"></p>
<p>這邊有個比較，紅線是訓練時間(看右邊的軸)，藍線是精準度(看左邊的軸)。<br>(全部的 example 都看就是正常 Gradient Descent)</p>
<p><img src="http://imgur.com/cZkL72s.jpg" alt="2-66"></p>
<h3 id="Recipe-for-Learning"><a href="#Recipe-for-Learning" class="headerlink" title="Recipe for Learning"></a>Recipe for Learning</h3><p>這邊主要講解一下在實際練習時會遇到的問題。</p>
<p><img src="http://imgur.com/TrD29wC.jpg" alt="2-68"></p>
<p>如果在 training data 的部分時就沒有好的結果:</p>
<p><img src="http://imgur.com/jyqTtWV.jpg" alt="2-70"></p>
<p><img src="http://imgur.com/9cQj3lN.jpg" alt="2-71"></p>
<p>關於 <strong>Overfitting</strong> 的小解釋 <a href="https://zh.wikipedia.org/wiki/%E9%81%8E%E9%81%A9" target="_blank" rel="noopener">維基百科</a>:  </p>
<p>我們從 training data 中得出的 best parameter ，並不代表我們在 test data 上也是如此適用。有可能因為過度符合 training data 導致在 test data 中有不好的結果。(可增加 training data 來解決)</p>
<p><img src="http://imgur.com/qpaMsoD.jpg" alt="2-72"></p>
<h2 id="總結"><a href="#總結" class="headerlink" title="總結"></a>總結</h2><p><img src="http://imgur.com/K75m9j4.jpg" alt="2-74"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://naivered.github.io/2016/10/01/Study_Notes/Machine Learning/Deep-and-Structured-L2-Notes-2/" data-id="cjemgtiqe00ssi8ugz8q2i989" class="article-share-link">Share</a>
      
        <a href="http://naivered.github.io/2016/10/01/Study_Notes/Machine Learning/Deep-and-Structured-L2-Notes-2/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/01/17/Study_Notes/Machine Learning/Machine-Learning-L1toL3-Notes/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Machine Learning - L1~L3 Notes
        
      </div>
    </a>
  
  
    <a href="/2016/09/18/Study_Notes/Machine Learning/Deep-and-Structured-L2-Notes-1/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Deep and Structured - L2 Notes(上)</div>
    </a>
  
</nav>

  
</article>


<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/03/11/Problem_Solving/UVa/UVa-10104-Euclid-Problem/">UVa 10104 - Euclid Problem</a>
          </li>
        
          <li>
            <a href="/2018/03/11/Problem_Solving/UVa/UVa-11420-Chest-of-Drawers/">UVa 11420 - Chest of Drawers</a>
          </li>
        
          <li>
            <a href="/2018/03/11/Problem_Solving/UVa/UVa-10819-Trouble-of-13-Dots/">UVa 10819 - Trouble of 13-Dots</a>
          </li>
        
          <li>
            <a href="/2018/03/11/Problem_Solving/UVa/UVa-796-Critical-Links/">UVa 796 - Critical Links</a>
          </li>
        
          <li>
            <a href="/2018/03/10/Problem_Solving/CodeForces/CodeForces-949A-Zebras/">CodeForces 949A - Zebras</a>
          </li>
        
          <li>
            <a href="/2018/03/10/Problem_Solving/UVa/UVa-10099-The-Tourist-Guide/">UVa 10099 - The Tourist Guide</a>
          </li>
        
          <li>
            <a href="/2018/03/10/Problem_Solving/UVa/UVa-10199-Tourist-Guide/">UVa 10199 - Tourist Guide</a>
          </li>
        
          <li>
            <a href="/2018/03/09/Problem_Solving/UVa/UVa-10336-Rank-the-Languages/">UVa 10336 - Rank the Languages</a>
          </li>
        
          <li>
            <a href="/2018/03/09/Problem_Solving/UVa/UVa-10067-Playing-with-Wheels/">UVa 10067 - Playing with Wheels</a>
          </li>
        
          <li>
            <a href="/2018/03/09/Problem_Solving/UVa/UVa-12382-Grid-of-Lamps/">UVa 12382 - Grid of Lamps</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Problem-Solving/">Problem Solving</a><span class="category-list-count">228</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Problem-Solving/CodeForces/">CodeForces</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Problem-Solving/UVa/">UVa</a><span class="category-list-count">223</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Problem-Solving/ZeroJudge/">ZeroJudge</a><span class="category-list-count">4</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/學習筆記/">學習筆記</a><span class="category-list-count">26</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/學習筆記/ML-Hung-yi-Lee/">ML(Hung-yi Lee)</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/學習筆記/Python/">Python</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/學習筆記/機器學習基石/">機器學習基石</a><span class="category-list-count">11</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/心情隨筆/">心情隨筆</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/網頁建置/">網頁建置</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/網頁建置/Hexo/">Hexo</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/讀書手札/">讀書手札</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/讀書手札/讀後感/">讀後感</a><span class="category-list-count">1</span></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a><span class="archive-list-count">19</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">February 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a><span class="archive-list-count">16</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a><span class="archive-list-count">48</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a><span class="archive-list-count">52</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a><span class="archive-list-count">18</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a><span class="archive-list-count">29</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a><span class="archive-list-count">20</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">February 2016</a><span class="archive-list-count">22</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">January 2016</a><span class="archive-list-count">3</span></li></ul>
    </div>
  </div>


  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 NaiveRed<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and Theme by <a href="https://github.com/hexojs/hexo-theme-landscape" target="_blank">landscape</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
</nav>
    
<script>
  var disqus_shortname = 'naivered';
  
  var disqus_url = 'http://naivered.github.io/2016/10/01/Study_Notes/Machine Learning/Deep-and-Structured-L2-Notes-2/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>

<!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
</body>
</html>