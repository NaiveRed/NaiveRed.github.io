<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Machine Learning - L1~L3 Notes | NaiveRed&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="前言同樣是 李宏毅 教授的課程 Machine Learning (2016,Fall)。稍作簡易筆記。">
<meta name="keywords" content="Machine Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Machine Learning - L1~L3 Notes">
<meta property="og:url" content="http://naivered.github.io/2017/01/17/Study_Notes/Machine Learning/Machine-Learning-L1toL3-Notes/index.html">
<meta property="og:site_name" content="NaiveRed&#39;s Blog">
<meta property="og:description" content="前言同樣是 李宏毅 教授的課程 Machine Learning (2016,Fall)。稍作簡易筆記。">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://imgur.com/fAItbHz.png">
<meta property="og:image" content="http://imgur.com/8e0Tled.png">
<meta property="og:image" content="http://imgur.com/Atd63hk.png">
<meta property="og:image" content="http://imgur.com/95WlWqB.png">
<meta property="og:image" content="http://imgur.com/uMKBawz.png">
<meta property="og:image" content="http://imgur.com/rp7t8pQ.png">
<meta property="og:image" content="http://imgur.com/NXPO1um.png">
<meta property="og:image" content="http://imgur.com/ZMUeYBh.png">
<meta property="og:image" content="http://imgur.com/jXzoaVx.png">
<meta property="og:image" content="http://imgur.com/RkjpHie.png">
<meta property="og:image" content="http://imgur.com/0eaGNiM.png">
<meta property="og:image" content="http://imgur.com/pEuFI7J.png">
<meta property="og:image" content="http://imgur.com/qbnf1Ja.png">
<meta property="og:image" content="http://imgur.com/zRCqkkv.png">
<meta property="og:updated_time" content="2017-01-21T13:33:25.847Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Machine Learning - L1~L3 Notes">
<meta name="twitter:description" content="前言同樣是 李宏毅 教授的課程 Machine Learning (2016,Fall)。稍作簡易筆記。">
<meta name="twitter:image" content="http://imgur.com/fAItbHz.png">
  
    <link rel="alternate" href="/atom.xml" title="NaiveRed&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-73951673-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">NaiveRed&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Don&#39;t Panic!</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/tags">Tags</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://naivered.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Study_Notes/Machine Learning/Machine-Learning-L1toL3-Notes" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/01/17/Study_Notes/Machine Learning/Machine-Learning-L1toL3-Notes/" class="article-date">
  <time datetime="2017-01-17T08:15:15.000Z" itemprop="datePublished">2017-01-17</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/學習筆記/">學習筆記</a>►<a class="article-category-link" href="/categories/學習筆記/ML-Hung-yi-Lee/">ML(Hung-yi Lee)</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Machine Learning - L1~L3 Notes
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
          
            <div id="toc" class="toc-article">
            <h2 class="toc-title">Contents</h2>
			  
                <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#前言"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Learning-Map-L1"><span class="toc-number">2.</span> <span class="toc-text">Learning Map (L1)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Regression-Case-Study-L2"><span class="toc-number">3.</span> <span class="toc-text">Regression: Case Study (L2)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Regularization"><span class="toc-number">3.1.</span> <span class="toc-text">Regularization</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Gradient-Descent-L3"><span class="toc-number">4.</span> <span class="toc-text">Gradient Descent (L3)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Adaptive-Learning-Rates"><span class="toc-number">4.1.</span> <span class="toc-text">Adaptive Learning Rates</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Adagrad"><span class="toc-number">4.1.1.</span> <span class="toc-text">Adagrad</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Stochastic-Gradient-Descent"><span class="toc-number">4.2.</span> <span class="toc-text">Stochastic Gradient Descent</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Feature-Scaling"><span class="toc-number">4.3.</span> <span class="toc-text">Feature Scaling</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Gradient-Descent-原理"><span class="toc-number">4.4.</span> <span class="toc-text">Gradient Descent 原理</span></a></li></ol></li></ol> 
              
            </div>
        
        <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>同樣是 李宏毅 教授的課程 <a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML16.html" target="_blank" rel="noopener">Machine Learning (2016,Fall)</a>。<br>稍作簡易筆記。</p>
<a id="more"></a>
<h1 id="Learning-Map-L1"><a href="#Learning-Map-L1" class="headerlink" title="Learning Map (L1)"></a>Learning Map (L1)</h1><p><img src="http://imgur.com/fAItbHz.png" alt="1-27"></p>
<p>在其餘 scenario 內也是可以做 Supervised Learning 裡的 task、method。 </p>
<p><strong>Transfer learning</strong> : 大致上就是利用已訓練好的模型來幫助新的訓練，這樣新的就不用從零開始訓練了。  </p>
<blockquote>
<p> focuses on storing knowledge gained while solving one problem and applying it to a different but related problem. For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks. - wikipedia</p>
</blockquote>
<p><strong>Reinforcement learning</strong> : 不像一般的訓練有輸入輸出，以下圖例子來看，就是直接下去與人對話，在依人的反應來判斷機器回應得好不好。  </p>
<p><img src="http://imgur.com/8e0Tled.png" alt="1-25"></p>
<h1 id="Regression-Case-Study-L2"><a href="#Regression-Case-Study-L2" class="headerlink" title="Regression: Case Study (L2)"></a>Regression: Case Study (L2)</h1><p>這邊影片有再解釋一下 Gradient Descent ，蠻清楚的。</p>
<p><img src="http://imgur.com/Atd63hk.png" alt="2-26"></p>
<p>越複雜的 model 可能在 training data 有更好的表現，但在 testing data 上卻不一定會更好，也就是 <strong>Overfitting</strong> 的問題。</p>
<p>這邊提到一個解決 overfitting 的方法，除了增加資料以外，還可以使用 <strong>Regularization</strong>。</p>
<h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h2><p><img src="http://imgur.com/95WlWqB.png" alt="2-34"></p>
<p>圖中的 L 就是 <strong>loss function</strong> (功用如同之前的 cost function，越小越好)。我們在其後加上了一項，我們也希望它能越小越好。  </p>
<p>這用意在於我們想要比較 <strong>smooth</strong> 的 function，也就是對於輸入的變化比較不敏感。$w_i$ 越接近 0 ，輸出對輸入就越不敏感。<br>我們就比較不會受一些雜訊所干擾而大幅的影響訓練出來的結果，太平滑的 function 也會失去其效果。<br>(此項不用考慮 bias 是因為其不影響 function 的平滑度)</p>
<p>接著是例子中使用此方法後的結果:</p>
<p><img src="http://imgur.com/uMKBawz.png" alt="2-35"></p>
<p>loss function 中有考慮原本的 <strong>error</strong> 和 <strong>smooth</strong> ，當 $\lambda$ 越大時，代表找出來的 function 越平滑。</p>
<p>明顯可以看到隨著 $\lambda$ 變大 ，training data 的 error 也越來越大，因為我們考慮 error 的部分變小了。但在 testing data 的部分則不然。</p>
<h1 id="Gradient-Descent-L3"><a href="#Gradient-Descent-L3" class="headerlink" title="Gradient Descent (L3)"></a>Gradient Descent (L3)</h1><p>可以看一下之前的筆記( Deep and Structured - L2) Gradient Descent 的部分，這邊不再重寫。</p>
<p>這邊介紹了幾個小 tip 來增進 Gradient Descent 的效果。 </p>
<h2 id="Adaptive-Learning-Rates"><a href="#Adaptive-Learning-Rates" class="headerlink" title="Adaptive Learning Rates"></a>Adaptive Learning Rates</h2><p><img src="http://imgur.com/rp7t8pQ.png" alt="3-6"></p>
<p>根據不同的參數給予不同的 learning rate ，一開始離目標很遠， learning rate 較大;開始接近目標後，就減小 learning rate 。</p>
<h3 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h3><p>根據先前的結果來更改 learning rate。<br>$\sigma^t$ 是先前所有微分的 <strong>root mean square</strong> 。 $\eta^t$ 則會隨著 update 的次數變小。</p>
<p><img src="http://imgur.com/NXPO1um.png" alt="3-7"></p>
<p><img src="http://imgur.com/ZMUeYBh.png" alt="3-8"></p>
<p>化簡 $\sqrt{t+1}$</p>
<p><img src="http://imgur.com/jXzoaVx.png" alt="3-9"></p>
<p>這裡可以發現一件事越大的 $g^t$ 代表越陡峭會有越大的步伐，可是在分母卻會導致步伐變小。<br>這邊直觀的解釋是造成 <strong>反差</strong> 的效果，雖然這次的值一樣，但之前出來的值($g^t$)的大小卻會影響這次的效果。<br>ex.10.1   10.2   10.3   0.1<br>ex.0.0001 0.0001 0.0001 0.1</p>
<p>(還有更正式的解釋在影片)</p>
<h2 id="Stochastic-Gradient-Descent"><a href="#Stochastic-Gradient-Descent" class="headerlink" title="Stochastic Gradient Descent"></a>Stochastic Gradient Descent</h2><p>( Deep and Structured - L2 )</p>
<h2 id="Feature-Scaling"><a href="#Feature-Scaling" class="headerlink" title="Feature Scaling"></a>Feature Scaling</h2><p>我們希望不同的 feature 分布範圍差不多。</p>
<p><img src="http://imgur.com/RkjpHie.png" alt="3-22"></p>
<p>原因在於，如果某項( $x_i$ )特別大的話，會導致其 $w_i$ 對 輸出 的影響變大，反之則是變小。  </p>
<p><img src="http://imgur.com/0eaGNiM.png" alt="3-23"></p>
<p>在還沒 scaling 時可以看到圖中 loss function ，在 $w_1$ 的方向比較平滑，在 $w_2$ 的方向比較陡峭。<br>scaling 後圖形呈現一個正圓，這樣在 update 時會比較容易朝著目標前進(圓心)。  </p>
<p>其中一種 scaling 的方法就是 <strong>標準化(standardizing)</strong> ，每個 data 的第 i 項減掉 全部 data 第 i 項的平均再除以它們的標準差。</p>
<p><img src="http://imgur.com/pEuFI7J.png" alt="3-24"></p>
<h2 id="Gradient-Descent-原理"><a href="#Gradient-Descent-原理" class="headerlink" title="Gradient Descent 原理"></a>Gradient Descent 原理</h2><p>之前 Taylor Series 的部分( Deep and Structured - L2 )。</p>
<p>這邊多說明一下這張圖:</p>
<p><img src="http://imgur.com/qbnf1Ja.png" alt="3-34"></p>
<p>為了使 $L(\theta)$ 的值最小，我們可以將 $(u,v)$ 和 $(\Delta{\theta_1},\Delta{\theta_2})$ 看成兩個向量。不用管 $s$，因為 $\theta$ 並不影響它。<br>然後兩向量做內積的值就會等於 $L(\theta)$ 。  </p>
<p>要讓此內積的值最小，就是讓它們夾 180 度  ( $cos(\pi)=-1$ )。<br>$(\Delta{\theta_1},\Delta{\theta_2})$ 的方向就是 $(u,v)$ 的反方向，然後調整長度到 d 的邊界，也就是乘上某個 constant( $-1 \times \eta$ )。<br>最後要找到那一個使 $L(\theta)$ 最小的點，就是利用圓點 $(a,b)$ 加上剛剛算出來的向量。</p>
<p>而這結果要精確取決於紅色圈圈的大小($d$)，直接的影響了 learning rate ，它們的值要 <strong>足夠小</strong>。</p>
<p><img src="http://imgur.com/zRCqkkv.png" alt="3-35"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://naivered.github.io/2017/01/17/Study_Notes/Machine Learning/Machine-Learning-L1toL3-Notes/" data-id="cjzzlg6nk001otougb3yonet8" class="article-share-link">Share</a>
      
        <a href="http://naivered.github.io/2017/01/17/Study_Notes/Machine Learning/Machine-Learning-L1toL3-Notes/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/01/19/Study_Notes/Machine Learning/Machine-Learning-L4-Notes/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Machine Learning - L4 Notes
        
      </div>
    </a>
  
  
    <a href="/2016/10/01/Study_Notes/Machine Learning/Deep-and-Structured-L2-Notes-2/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Deep and Structured - L2 Notes(下)</div>
    </a>
  
</nav>

  
</article>


<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/05/27/Chore/VS-Code-for-C-and-CPP/">VS Code for C and CPP</a>
          </li>
        
          <li>
            <a href="/2018/05/26/Problem_Solving/UVa/UVa-10158-War/">UVa 10158 - War</a>
          </li>
        
          <li>
            <a href="/2018/05/26/Problem_Solving/UVa/UVa-10528-Major-Scales/">UVa 10528 - Major Scales</a>
          </li>
        
          <li>
            <a href="/2018/05/21/Problem_Solving/UVa/UVa-12908-The-book-thief/">UVa 12908 - The book thief</a>
          </li>
        
          <li>
            <a href="/2018/05/20/For_Fun/The-Cannon-of-Gintama-by-openCV/">OpenCV 噴射阿姆斯特朗砲繪製練習</a>
          </li>
        
          <li>
            <a href="/2018/05/20/Problem_Solving/UVa/UVa-11235-Frequent-values/">UVa 11235 - Frequent values</a>
          </li>
        
          <li>
            <a href="/2018/05/20/Problem_Solving/UVa/UVa-11223-O-dah-dah-dah/">UVa 11223 - O: dah dah dah!</a>
          </li>
        
          <li>
            <a href="/2018/04/23/Problem_Solving/UVa/UVa-394-Mapmaker/">UVa 394 - Mapmaker</a>
          </li>
        
          <li>
            <a href="/2018/04/13/Problem_Solving/UVa/UVa-10901-Ferry-Loading-III/">UVa 10901 - Ferry Loading III</a>
          </li>
        
          <li>
            <a href="/2018/04/11/Problem_Solving/UVa/UVa-1730-Sum-of-MSLCM/">UVa 1730 - Sum of MSLCM</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Chore/">Chore</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/For-Fun/">For Fun</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Problem-Solving/">Problem Solving</a><span class="category-list-count">258</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Problem-Solving/CodeForces/">CodeForces</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Problem-Solving/UVa/">UVa</a><span class="category-list-count">253</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Problem-Solving/ZeroJudge/">ZeroJudge</a><span class="category-list-count">4</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/學習筆記/">學習筆記</a><span class="category-list-count">26</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/學習筆記/ML-Hung-yi-Lee/">ML(Hung-yi Lee)</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/學習筆記/Python/">Python</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/學習筆記/機器學習基石/">機器學習基石</a><span class="category-list-count">11</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/心情隨筆/">心情隨筆</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/讀書手札/">讀書手札</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/讀書手札/讀後感/">讀後感</a><span class="category-list-count">1</span></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a><span class="archive-list-count">40</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">February 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a><span class="archive-list-count">16</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a><span class="archive-list-count">48</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a><span class="archive-list-count">51</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a><span class="archive-list-count">18</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a><span class="archive-list-count">29</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a><span class="archive-list-count">20</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">February 2016</a><span class="archive-list-count">22</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">January 2016</a><span class="archive-list-count">3</span></li></ul>
    </div>
  </div>


  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 NaiveRed<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and Theme by <a href="https://github.com/hexojs/hexo-theme-landscape" target="_blank">landscape</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
</nav>
    
<script>
  var disqus_shortname = 'naivered';
  
  var disqus_url = 'http://naivered.github.io/2017/01/17/Study_Notes/Machine Learning/Machine-Learning-L1toL3-Notes/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>

<!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
</body>
</html>