<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Machine Learning - L6 Notes | NaiveRed&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Classification: Logistic Regression (L6)另一種方法。">
<meta name="keywords" content="Machine Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Machine Learning - L6 Notes">
<meta property="og:url" content="http://naivered.github.io/2017/01/21/Study_Notes/Machine Learning/Machine-Learning-L6-Notes/index.html">
<meta property="og:site_name" content="NaiveRed&#39;s Blog">
<meta property="og:description" content="Classification: Logistic Regression (L6)另一種方法。">
<meta property="og:image" content="http://imgur.com/e2XoUE1.png">
<meta property="og:image" content="http://imgur.com/ZoKhkUV.png">
<meta property="og:image" content="http://imgur.com/vdbNa2t.png">
<meta property="og:image" content="http://imgur.com/LSZYRAd.png">
<meta property="og:image" content="http://imgur.com/1tD2ZI0.png">
<meta property="og:image" content="http://imgur.com/SsLwgUg.png">
<meta property="og:image" content="http://imgur.com/0JIY09z.png">
<meta property="og:image" content="http://imgur.com/cEs0kV4.png">
<meta property="og:image" content="http://imgur.com/jqhp77Q.png">
<meta property="og:image" content="http://imgur.com/yn0uW3r.png">
<meta property="og:image" content="http://imgur.com/zGzILpn.png">
<meta property="og:image" content="http://imgur.com/CNFaoR6.png">
<meta property="og:image" content="http://imgur.com/Qtz5Fyd.png">
<meta property="og:image" content="http://imgur.com/SHkWRtC.png">
<meta property="og:image" content="http://imgur.com/M8ldeeH.png">
<meta property="og:image" content="http://imgur.com/jYbMa9c.png">
<meta property="og:image" content="http://imgur.com/qw7Ojm5.png">
<meta property="og:updated_time" content="2017-01-27T10:03:21.613Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Machine Learning - L6 Notes">
<meta name="twitter:description" content="Classification: Logistic Regression (L6)另一種方法。">
<meta name="twitter:image" content="http://imgur.com/e2XoUE1.png">
  
    <link rel="alternate" href="/atom.xml" title="NaiveRed&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-73951673-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">NaiveRed&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Don&#39;t Panic!</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/tags">Tags</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://naivered.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Study_Notes/Machine Learning/Machine-Learning-L6-Notes" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/01/21/Study_Notes/Machine Learning/Machine-Learning-L6-Notes/" class="article-date">
  <time datetime="2017-01-21T07:05:14.000Z" itemprop="datePublished">2017-01-21</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/學習筆記/">學習筆記</a>►<a class="article-category-link" href="/categories/學習筆記/ML-Hung-yi-Lee/">ML(Hung-yi Lee)</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Machine Learning - L6 Notes
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
          
            <div id="toc" class="toc-article">
            <h2 class="toc-title">Contents</h2>
			  
                <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Classification-Logistic-Regression-L6"><span class="toc-number">1.</span> <span class="toc-text">Classification: Logistic Regression (L6)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Step-1-Function-Set"><span class="toc-number">1.1.</span> <span class="toc-text">Step 1 : Function Set</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Step-2-Goodness-of-a-Function"><span class="toc-number">1.2.</span> <span class="toc-text">Step 2 : Goodness of a Function</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#cross-entropy-v-s-square-error"><span class="toc-number">1.2.1.</span> <span class="toc-text">cross entropy v.s square error</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Step-3-Find-the-best-function"><span class="toc-number">1.3.</span> <span class="toc-text">Step 3 : Find the best function</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Discriminative-v-s-Generative"><span class="toc-number">1.4.</span> <span class="toc-text">Discriminative v.s. Generative</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Limitation-of-Logistic-Regression"><span class="toc-number">1.5.</span> <span class="toc-text">Limitation of Logistic Regression</span></a></li></ol></li></ol> 
              
            </div>
        
        <h1 id="Classification-Logistic-Regression-L6"><a href="#Classification-Logistic-Regression-L6" class="headerlink" title="Classification: Logistic Regression (L6)"></a>Classification: Logistic Regression (L6)</h1><p>另一種方法。</p>
<a id="more"></a>
<h2 id="Step-1-Function-Set"><a href="#Step-1-Function-Set" class="headerlink" title="Step 1 : Function Set"></a>Step 1 : Function Set</h2><p>如果我們現在要求的 posterior probability 就是將 $z = w\cdot x + b$ 代進 <strong>sigmoid function</strong> 的結果。  </p>
<p>我們的 function set 就是由不同 $w,b$ 的 function 所組成。</p>
<p><img src="http://imgur.com/e2XoUE1.png" alt="6-2"></p>
<p>用圖形來表示:</p>
<p><img src="http://imgur.com/ZoKhkUV.png" alt="6-3"></p>
<p>而這樣的作法叫做 <strong>Logistic Regression</strong>。</p>
<p>比較一下最開始講的 <strong>Linear Regression</strong>。</p>
<p><img src="http://imgur.com/vdbNa2t.png" alt="6-4"></p>
<p>Logistic Regression 會通過 sigmoid function 所以 output 會介於 <strong>0 ~ 1</strong>。<br>Linear Regression 則可能是任何值。</p>
<h2 id="Step-2-Goodness-of-a-Function"><a href="#Step-2-Goodness-of-a-Function" class="headerlink" title="Step 2 : Goodness of a Function"></a>Step 2 : Goodness of a Function</h2><p>給定 $w,b$ 後，我們就能求出產生這樣一筆 training data 的機率為何，<br>也就是圖中的 $L(w,b)$ ，likelihood function。  </p>
<p>而其中最好的 $w,b$ 就是能使 $L(w,b)$ <strong>最大化</strong> 的。  </p>
<p><img src="http://imgur.com/LSZYRAd.png" alt="6-5"></p>
<p>為了方便計算我們可以把它轉換成找 $-lnL(w,b)$ 的 <strong>最小值</strong>。</p>
<p><img src="http://imgur.com/1tD2ZI0.png" alt="6-6"></p>
<p>而與 linear 在 <strong>loss function</strong> 上是 <strong>不一樣</strong> 的，<br>logistic 需要使用 <strong>cross entropy</strong> ，而 linear 的則是之前就看過的 <strong>square error</strong>。  </p>
<p><img src="http://imgur.com/SsLwgUg.png" alt="6-8"></p>
<h3 id="cross-entropy-v-s-square-error"><a href="#cross-entropy-v-s-square-error" class="headerlink" title="cross entropy v.s square error"></a>cross entropy v.s square error</h3><p>(數學推導部分就不貼了)</p>
<p><img src="http://imgur.com/0JIY09z.png" alt="6-15"></p>
<p>假設中間就是我們的目標(function)，其 loss 值很小。  </p>
<p>用 square error ，如果產生出的結果離目標很近，它微分的值自然 <strong>很小</strong>，<br>然而在離目標很遠的時候，它微分的值仍然 <strong>很小</strong>，導致非常平坦，在 update 時會很卡(步伐小)。<br>我們也不能隨意更改 learning rate 因為在離目標很近，我們需要較小的步伐。</p>
<p>如果用 cross entropy ，距離目標越遠，微分值則越大，在 update 參數時速度越快(步伐越大)。</p>
<h2 id="Step-3-Find-the-best-function"><a href="#Step-3-Find-the-best-function" class="headerlink" title="Step 3 : Find the best function"></a>Step 3 : Find the best function</h2><p>接下來要做的就是要找一個最好的 function ，也就是要去最小化我們的 $-lnL(w,b)$。<br>利用 gradient descent(對 $-lnL(w,b)$ 做偏微分然後 update $w_i$ ):  </p>
<p><img src="http://imgur.com/cEs0kV4.png" alt="6-11"></p>
<p>省略中間的過程，最後一項中間(紫線)，它代表著我們 $f$ 產生出來的結果和理想的差距有多大，差越多我們 update 的量就會越大。</p>
<p>在 linear regression 上，兩者的 update 算式是 <strong>一樣</strong> 的，<br>差別在於 $\hat{y}^n$，logistic 的會是 <strong>0 或 1</strong> ，而 linear 的會是任意實數。<br>還有 $f$ 的輸出，logistic 的會是 <strong>0~1</strong> ，而 linear 的會是任意實數。</p>
<p><img src="http://imgur.com/jqhp77Q.png" alt="6-12"></p>
<h2 id="Discriminative-v-s-Generative"><a href="#Discriminative-v-s-Generative" class="headerlink" title="Discriminative v.s. Generative"></a>Discriminative v.s. Generative</h2><p>上一章節(L5)所講的是利用常態分布(Gaussian distribution) 來描述 Posterior Probability 的方法，稱為 <strong>Generative</strong> model 。(covariance matrix 設成是共用的)<br>如果是 Logistic Regression 的話，我們稱之為 <strong>Discriminative</strong> model。</p>
<p><img src="http://imgur.com/yn0uW3r.png" alt="6-16"></p>
<p>如果是 Logistic Regression ，我們可以直接去把 $w,b$ 找出來(gradient descent)。<br>如果是 Generative model 則是先算出那些參數，再代進去求 $w,b$ 。  </p>
<p>它們的 function set 和 training data 是一樣的，但因為我們做了不同的假設，所以最後找出來的參數( $w,b$ )會是不一樣的。<br>(我們在 Logistic Regression 沒有對機率分布做其他假設)</p>
<p>而哪一個產生的結果會比較好呢？用一個簡單的例子來看。</p>
<p><img src="http://imgur.com/zGzILpn.png" alt="6-18"></p>
<p>每一個 class 都有兩個 feature，當都是 1 的時候就是 class 1 ，另外三種是 class 2。  </p>
<p>我們利用 <strong>Naive Bayes</strong> 來看看， 當 testing data 的兩個 feature 都是 1 時，屬於哪個 class 的機率比較高？<br>我們假設所有 feature 是獨立的，那 x 從 $C_i$ 產生出來的機率，就會等於其各個 feature 從 $C_i$ 產生出來的機率。</p>
<p>算出來各項後，我們就可以來算 x 屬於 class 1 的條件機率了。($&lt;0.5$)</p>
<p><img src="http://imgur.com/CNFaoR6.png" alt="6-20"></p>
<p>結果跟我們預想的不太一樣，對 naive bayes 來說它覺得這筆資料應該屬於 class 2 ，這是因為 naive bayes 自行腦補了 class 2 裡有這樣一筆資料(ㄏㄏ…)。<br>同樣的在 Generative 裡我們也自行假設了一些狀況，通常腦補會帶來比較差的效果。</p>
<p>何時 Generative 會比較好呢？</p>
<p><img src="http://imgur.com/Qtz5Fyd.png" alt="6-21"></p>
<ol>
<li><p>因為 discriminative 受資料量的影響比較大。所以在資料量較少時，generative 可能會效果比較好，因為它可能會遵從自己的假設，而無視資料。</p>
</li>
<li><p>資料本身有雜訊，而此時自行的假設可能會帶來較好的結果。</p>
</li>
<li><p>…</p>
</li>
</ol>
<h2 id="Limitation-of-Logistic-Regression"><a href="#Limitation-of-Logistic-Regression" class="headerlink" title="Limitation of Logistic Regression"></a>Limitation of Logistic Regression</h2><p>有時會有無法學習的情形，像是圖中的例子就做不到，我們找不到一條線來分紅和藍的點。<br>(在 Deep and Structured L2 有)</p>
<p><img src="http://imgur.com/SHkWRtC.png" alt="6-24"></p>
<p>此時我們就可以利用串接 Logistic Regression ，前半部分是在做 <strong>Feature Transformation</strong> ，我們可以得到另外一組 feature，後半部分則是 <strong>classification</strong> 。</p>
<p><img src="http://imgur.com/M8ldeeH.png" alt="6-27"></p>
<p>(圖中座標有誤)<br><img src="http://imgur.com/jYbMa9c.png" alt="6-29">  </p>
<p>此時就可以做到從中分一條線了。</p>
<p>而這樣子把 Logistic Regression 接在一起，<br>每一個 Logistic Regression 叫做一個 <strong>Neuron</strong>，很多個 Neuron 串起來就叫 <strong>Neural Network</strong> 。<br>這樣子的東西就叫做 <strong>Deep Learning</strong>。  </p>
<p><img src="http://imgur.com/qw7Ojm5.png" alt="6-30"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://naivered.github.io/2017/01/21/Study_Notes/Machine Learning/Machine-Learning-L6-Notes/" data-id="cjaovpmd9001ifsugi4z15hcr" class="article-share-link">Share</a>
      
        <a href="http://naivered.github.io/2017/01/21/Study_Notes/Machine Learning/Machine-Learning-L6-Notes/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/02/23/Study_Notes/Machine Learning/Machine-Learning-L7-Notes/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Machine Learning - L7 Notes
        
      </div>
    </a>
  
  
    <a href="/2017/01/20/Study_Notes/Machine Learning/Machine-Learning-L5-Notes/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Machine Learning - L5 Notes</div>
    </a>
  
</nav>

  
</article>


<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/12/01/Diary/20171201-Master-application-record-2/">資工、碩士、推甄 (下)</a>
          </li>
        
          <li>
            <a href="/2017/12/01/Diary/20171201-Master-application-record-1/">資工、碩士、推甄 (上)</a>
          </li>
        
          <li>
            <a href="/2017/10/22/Book/20171022-DarkMatter-Review-Ep1/">《人生複本》如果當初我 | Ep.1</a>
          </li>
        
          <li>
            <a href="/2017/03/24/Study_Notes/Machine Learning/ML17-Hello-world-Notes/">ML17 - &quot;Hello World&quot; Notes</a>
          </li>
        
          <li>
            <a href="/2017/03/17/Study_Notes/Machine Learning/Deep-and-Structured-2017-L2-Notes/">Deep and Structured(2017) - L2 Notes</a>
          </li>
        
          <li>
            <a href="/2017/03/16/Study_Notes/Machine Learning/Deep-and-Structured-2017-L1-Notes/">Deep and Structured(2017) - L1 Notes</a>
          </li>
        
          <li>
            <a href="/2017/03/02/Study_Notes/Python/keras-theano-install-recording/">Keras,theano 安裝紀錄</a>
          </li>
        
          <li>
            <a href="/2017/02/26/Study_Notes/Python/Deep-Learning-Prerequisites-Notes/">Deep Learning Prerequisites - Notes</a>
          </li>
        
          <li>
            <a href="/2017/02/26/Study_Notes/Machine Learning/Machine-Learning-L9-Notes/">Machine Learning - L9 Notes</a>
          </li>
        
          <li>
            <a href="/2017/02/24/Study_Notes/Machine Learning/Machine-Learning-L8-Notes/">Machine Learning - L8 Notes</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Problem-Solving/">Problem Solving</a><span class="category-list-count">204</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Problem-Solving/UVa/">UVa</a><span class="category-list-count">200</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Problem-Solving/ZeroJudge/">ZeroJudge</a><span class="category-list-count">4</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/學習筆記/">學習筆記</a><span class="category-list-count">26</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/學習筆記/ML-Hung-yi-Lee/">ML(Hung-yi Lee)</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/學習筆記/Python/">Python</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/學習筆記/機器學習基石/">機器學習基石</a><span class="category-list-count">11</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/心情隨筆/">心情隨筆</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/網頁建置/">網頁建置</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/網頁建置/Hexo/">Hexo</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/讀書手札/">讀書手札</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/讀書手札/讀後感/">讀後感</a><span class="category-list-count">1</span></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">February 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a><span class="archive-list-count">16</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a><span class="archive-list-count">48</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a><span class="archive-list-count">52</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a><span class="archive-list-count">18</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a><span class="archive-list-count">29</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a><span class="archive-list-count">20</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">February 2016</a><span class="archive-list-count">22</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">January 2016</a><span class="archive-list-count">3</span></li></ul>
    </div>
  </div>


  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 NaiveRed<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and Theme by <a href="https://github.com/hexojs/hexo-theme-landscape" target="_blank">landscape</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
</nav>
    
<script>
  var disqus_shortname = 'naivered';
  
  var disqus_url = 'http://naivered.github.io/2017/01/21/Study_Notes/Machine Learning/Machine-Learning-L6-Notes/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>

<!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
</body>
</html>