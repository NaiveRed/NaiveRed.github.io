<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Machine Learning - L5 Notes | NaiveRed&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="前言特別說明一下，這一篇實在是寫得很無力，很多地方是一頭霧水的…只能開學再問問了。">
<meta name="keywords" content="Machine Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Machine Learning - L5 Notes">
<meta property="og:url" content="http://naivered.github.io/2017/01/20/Study_Notes/Machine Learning/Machine-Learning-L5-Notes/index.html">
<meta property="og:site_name" content="NaiveRed&#39;s Blog">
<meta property="og:description" content="前言特別說明一下，這一篇實在是寫得很無力，很多地方是一頭霧水的…只能開學再問問了。">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://imgur.com/sc41U4F.png">
<meta property="og:image" content="http://imgur.com/XNpDcFG.png">
<meta property="og:image" content="http://imgur.com/4IoIHj2.png">
<meta property="og:image" content="http://imgur.com/dgkzpve.png">
<meta property="og:image" content="http://imgur.com/0VPlcnJ.png">
<meta property="og:image" content="http://imgur.com/kTqIbbl.png">
<meta property="og:image" content="http://imgur.com/J5YvyH6.png">
<meta property="og:image" content="http://imgur.com/PxYswmB.png">
<meta property="og:image" content="http://imgur.com/zOe5fKd.png">
<meta property="og:image" content="http://imgur.com/PnzKOMy.png">
<meta property="og:image" content="http://imgur.com/ovGbVx2.png">
<meta property="og:image" content="http://imgur.com/61bj4tz.png">
<meta property="og:image" content="http://imgur.com/4IjPqSm.png">
<meta property="og:image" content="http://imgur.com/lAsk2Uy.png">
<meta property="og:image" content="http://imgur.com/ctDzyF3.png">
<meta property="og:image" content="http://imgur.com/zLaGMBq.png">
<meta property="og:image" content="http://imgur.com/whMVJXs.png">
<meta property="og:image" content="http://imgur.com/GPt1ulq.png">
<meta property="og:image" content="http://imgur.com/b6WDyBz.png">
<meta property="og:updated_time" content="2017-01-27T07:52:10.483Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Machine Learning - L5 Notes">
<meta name="twitter:description" content="前言特別說明一下，這一篇實在是寫得很無力，很多地方是一頭霧水的…只能開學再問問了。">
<meta name="twitter:image" content="http://imgur.com/sc41U4F.png">
  
    <link rel="alternate" href="/atom.xml" title="NaiveRed&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-73951673-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">NaiveRed&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Don&#39;t Panic!</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/tags">Tags</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://naivered.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Study_Notes/Machine Learning/Machine-Learning-L5-Notes" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/01/20/Study_Notes/Machine Learning/Machine-Learning-L5-Notes/" class="article-date">
  <time datetime="2017-01-20T07:05:14.000Z" itemprop="datePublished">2017-01-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/學習筆記/">學習筆記</a>►<a class="article-category-link" href="/categories/學習筆記/ML-Hung-yi-Lee/">ML(Hung-yi Lee)</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Machine Learning - L5 Notes
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
          
            <div id="toc" class="toc-article">
            <h2 class="toc-title">Contents</h2>
			  
                <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#前言"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Classification-Probabilistic-Generative-Model-L5"><span class="toc-number">2.</span> <span class="toc-text">Classification: Probabilistic Generative Model (L5)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Regression"><span class="toc-number">2.1.</span> <span class="toc-text">Regression</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#其他方法"><span class="toc-number">2.2.</span> <span class="toc-text">其他方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Generative-model"><span class="toc-number">2.3.</span> <span class="toc-text">Generative model</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Gaussian-distribution"><span class="toc-number">2.3.1.</span> <span class="toc-text">Gaussian distribution</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Maximum-Likelihood"><span class="toc-number">2.3.2.</span> <span class="toc-text">Maximum Likelihood</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#例子"><span class="toc-number">2.4.</span> <span class="toc-text">例子</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#改進成-linear-model"><span class="toc-number">2.4.1.</span> <span class="toc-text">改進成 linear model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#結論"><span class="toc-number">2.4.2.</span> <span class="toc-text">結論</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Probability-Distribution"><span class="toc-number">2.5.</span> <span class="toc-text">Probability Distribution</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Posterior-Probability"><span class="toc-number">2.6.</span> <span class="toc-text">Posterior Probability</span></a></li></ol></li></ol> 
              
            </div>
        
        <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>特別說明一下，這一篇實在是寫得很無力，很多地方是一頭霧水的…<br>只能開學再問問了。</p>
<a id="more"></a>
<h1 id="Classification-Probabilistic-Generative-Model-L5"><a href="#Classification-Probabilistic-Generative-Model-L5" class="headerlink" title="Classification: Probabilistic Generative Model (L5)"></a>Classification: Probabilistic Generative Model (L5)</h1><p>很多地方都被我跳過了….</p>
<h2 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h2><p>如果把 Classification 直接用 Regression 來解，有可能會發生:</p>
<p>我們以二元分類為例，output 接近 1 就是第一類 ; output 接近 -1 就是第二類。</p>
<p><img src="http://imgur.com/sc41U4F.png" alt="5-7"></p>
<p>從圖中可以看出綠色的線是較好的，但如果用 regression 下去學，它會產生紫色那條。<br>因為對於右下角那筆資料(第一類)而言，它們在綠線的情況下，是離 1 很遠的。而 Regression 會希望第一類的資料輸出越接近 1 越好。它會懲罰那些太正確的資料(&gt;&gt;1)。</p>
<p>也就是說 Regression 中定義 function 好壞的方式對分類來說是不適用的。<br>還有在多元分類的情況下，如果各類中間並沒有關係存在的話，結果也不會好。</p>
<h2 id="其他方法"><a href="#其他方法" class="headerlink" title="其他方法"></a>其他方法</h2><p>可以用下圖中的這種方法 。<br>而 loss function 就改成我們的 output 不符合 training data 的次數。</p>
<p><img src="http://imgur.com/XNpDcFG.png" alt="5-8"></p>
<p>如何找到這最好的 function ，可以用如 Perceptron、SVM 等方法。但這邊我們先用機率的角度來解。  </p>
<h2 id="Generative-model"><a href="#Generative-model" class="headerlink" title="Generative model"></a>Generative model</h2><p>把 class 1、2 看成兩個箱子，</p>
<p><img src="http://imgur.com/4IoIHj2.png" alt="5-9"></p>
<p>我們只要可以算出圖中紅框中的數值，就能得知 $x$ 屬於各類的機率為何。</p>
<p><img src="http://imgur.com/dgkzpve.png" alt="5-10"></p>
<p>而這樣子的作法叫做 <strong>Generative Model</strong> ，原因是我們可以拿這個 model 來產生出 $x$ ，也就是可以算出某一個 $x$ 出現的機率，就能知道它的 distribution 。(式子在上圖的最下面)</p>
<p>我們可以假設所有的資料都是從 <strong>Gaussian distribution</strong> 取樣出來的，當前看到的 training data 只是取樣的冰山一角，</p>
<p><img src="http://imgur.com/0VPlcnJ.png" alt="5-13"></p>
<p>所以現在要做的就是，根據現有的資料來找出這個 Gaussian distribution。</p>
<h3 id="Gaussian-distribution"><a href="#Gaussian-distribution" class="headerlink" title="Gaussian distribution"></a>Gaussian distribution</h3><p>Input 是 vector $x$(寶可夢的各項素值)。output 是 $x$ 產生的機率(機率密度)。<br>主要取決於 <strong>mean</strong> $\mu$ 和 <strong>covariance matrix</strong> $\Sigma$ 。 </p>
<p><img src="http://imgur.com/kTqIbbl.png" alt="5-14"></p>
<p>接著就是要用這些資料算出 $\mu$ 和 $\Sigma$ ，<br>這樣當我們有一個新的 $x$ 時，就能代進 Gaussian distribution 的式子裡，求出這個 $x$ 被取樣出來的機率了。</p>
<p><img src="http://imgur.com/J5YvyH6.png" alt="5-16"></p>
<h3 id="Maximum-Likelihood"><a href="#Maximum-Likelihood" class="headerlink" title="Maximum Likelihood"></a>Maximum Likelihood</h3><p>任何一個 Gaussian (不同的 $\mu$ 和 $\Sigma$ )都有可能產生出我們現在的這些資料，只是有些點機率低，有些高而已。  </p>
<p>因此不同的 Gaussian 產生出現在這些資料的機率是不一樣的 =&gt; different likelihood  </p>
<p><img src="http://imgur.com/PxYswmB.png" alt="5-17"></p>
<p>這裡的 Likelihood function ( $L(\mu,\Sigma)$ ) ，輸入是 Gaussian 的 <strong>$\mu$ 和 $\Sigma$</strong> ，輸出則是 Gaussian <strong>「產生這些資料的機率」</strong> 為何。(圖中的例子來看，資料就是那79個點)<br>而這邊產生出各個點的機率是獨立的，所以 $L(\mu,\Sigma)$ 就是將產生各個點的機率 $f_{\mu,\Sigma}(x)$ 相乘起來。</p>
<p>現在我們要找的就是一組 $\mu,\Sigma$ ，使 $L(\mu,\Sigma)$ 的值為最大，也就是使這個 Gaussian 產生出資料中 79 個點的 likelihood 是最大的( 產生這些資料的機率最高的一組參數 ) ，<br>寫作 <span>$({\mu}^*, \Sigma^*)$</span><!-- Has MathJax -->。 =&gt; <strong>maximum likelihood</strong><br>我們就把這個 Gaussian 當作是產生出我們資料的 Gaussian。</p>
<p><span>${\mu}^*$</span><!-- Has MathJax --> 就會是這79個 $x^n$ 的 <strong>平均</strong>。<br><span>$\Sigma^*$</span><!-- Has MathJax --> 則是它們的 <strong>共變異數</strong>(Covariance)。</p>
<p><img src="http://imgur.com/zOe5fKd.png" alt="5-18"></p>
<p>這邊補充說明一下:    </p>
<ul>
<li><p><strong>機率( Probability )</strong></p>
<blockquote>
<p><em>Probability</em> is used <strong>before</strong> data are available to describe possible future outcomes given a fixed value for the parameter (or parameter vector). - wikipedia    </p>
</blockquote>
<p>在已知一些參數的情況下，用來預測接下來得到的 <strong>結果</strong> 的函數。</p>
</li>
<li><p><strong>似然性( Likelihood )</strong> (Likelihood function)  </p>
<blockquote>
<p><em>Likelihood</em> is used <strong>after</strong> data are available to describe a function of a parameter (or parameter vector) for a given outcome. - wikipedia  </p>
</blockquote>
<p>在已知某些觀測所得到的結果時，用來估計相關 <strong>參數</strong> 的函數。</p>
</li>
</ul>
<h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>(水系和一般系的寶可夢)</p>
<p>先求出它們的 $\mu$ 和 $\Sigma$。</p>
<p><img src="http://imgur.com/PnzKOMy.png" alt="5-19"></p>
<p>接著就可以來看某一個 $x$ 屬於各類的機率了。 </p>
<p><img src="http://imgur.com/ovGbVx2.png" alt="5-11"></p>
<p><div id="generative"></div><br><img src="http://imgur.com/61bj4tz.png" alt="5-20"></p>
<p>(&gt;0.5 就是水系)<br>然而就算增加到 7 個 feature ，其正確率仍舊不高。 </p>
<p><img src="http://imgur.com/4IjPqSm.png" alt="5-21"></p>
<h3 id="改進成-linear-model"><a href="#改進成-linear-model" class="headerlink" title="改進成 linear model"></a>改進成 linear model</h3><p>而這是因為在不同 class 下，我們給它不同的參數，會導致 model 太複雜而 variance 過高，容易 <strong>overfitting</strong>。<br>所以我們可以給這兩個 class <strong>同一個</strong> covariance matrix ，這樣就能減少它的參數。(仍舊是不同 Gaussian ，$\mu$ 不同)</p>
<p>可以把式子寫成這樣:</p>
<p>$\mu$ 的算法和原本一樣，把某系的 x 加起來做平均。<br>當是水系時就用 $\mu^1$，一般系就用 $\mu^2$，(不是全部乘在一起)。  </p>
<p>$\Sigma$ 的就要改成圖片中那樣。</p>
<p><img src="http://imgur.com/lAsk2Uy.png" alt="5-23"></p>
<p>使用同一個 covariance matrix ，會使分類的線變成一直線，我們稱之為 <strong>linear</strong> model。<br>再把其他 feature 考慮進去後，正確率就有大幅提升了。</p>
<p><img src="http://imgur.com/ctDzyF3.png" alt="5-24"></p>
<h3 id="結論"><a href="#結論" class="headerlink" title="結論"></a>結論</h3><p>最後統整出來的步驟就是:</p>
<p><img src="http://imgur.com/zLaGMBq.png" alt="5-25"></p>
<h2 id="Probability-Distribution"><a href="#Probability-Distribution" class="headerlink" title="Probability Distribution"></a>Probability Distribution</h2><p>要用甚麼樣的機率模型取決於資料，例如是 binary feature 的話，我們就可以用 <strong>Bernoulli distribution</strong> 。</p>
<p>如果我們假設的是所有維度的 feature 都是 <strong>獨立</strong> 的，這樣就是 <strong>Naive Bayes Classifier</strong>。<br>在 $C_1$ 中 $x$ 產生的機率( $P(x|C_1)$ )，就可以寫成各項 feature 在 $C_1$ 中出現的機率相乘。</p>
<p><img src="http://imgur.com/whMVJXs.png" alt="5-26"></p>
<p>(在寶可夢的例子中，這樣的方法太過簡單(bias 較大)，準確率不高)</p>
<h2 id="Posterior-Probability"><a href="#Posterior-Probability" class="headerlink" title="Posterior Probability"></a>Posterior Probability</h2><p>(Posterior Probability: 基本上就是 條件機率)  </p>
<p>最後求出來的 $P(C_1|x)$ ，x 屬於某類的機率，<br>就會是將 $w \cdot x + b$ 代進 <strong>sigmoid function</strong> 後的結果。<br>(推導過程省略)</p>
<p><img src="http://imgur.com/GPt1ulq.png" alt="5-27"></p>
<p>$z = w \cdot x + b$</p>
<p><img src="http://imgur.com/b6WDyBz.png" alt="5-33"></p>
<p>在 Generative model 中，我們做的是先用某些方法找到式子中的各項參數，在代進去求機率。(上面<a href="#generative">小節</a>)  </p>
<p>那如果試著直接找 $w,b$ 呢？那就是下一章節要講的 logistic regression。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://naivered.github.io/2017/01/20/Study_Notes/Machine Learning/Machine-Learning-L5-Notes/" data-id="cjzzn9hl4001jk4ughrwvait8" class="article-share-link">Share</a>
      
        <a href="http://naivered.github.io/2017/01/20/Study_Notes/Machine Learning/Machine-Learning-L5-Notes/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/01/21/Study_Notes/Machine Learning/Machine-Learning-L6-Notes/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Machine Learning - L6 Notes
        
      </div>
    </a>
  
  
    <a href="/2017/01/19/Study_Notes/Machine Learning/Machine-Learning-L4-Notes/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Machine Learning - L4 Notes</div>
    </a>
  
</nav>

  
</article>


<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/05/27/Chore/VS-Code-for-C-and-CPP/">VS Code for C and CPP</a>
          </li>
        
          <li>
            <a href="/2018/05/26/Problem_Solving/UVa/UVa-10158-War/">UVa 10158 - War</a>
          </li>
        
          <li>
            <a href="/2018/05/26/Problem_Solving/UVa/UVa-10528-Major-Scales/">UVa 10528 - Major Scales</a>
          </li>
        
          <li>
            <a href="/2018/05/21/Problem_Solving/UVa/UVa-12908-The-book-thief/">UVa 12908 - The book thief</a>
          </li>
        
          <li>
            <a href="/2018/05/20/For_Fun/The-Cannon-of-Gintama-by-openCV/">OpenCV 噴射阿姆斯特朗砲繪製練習</a>
          </li>
        
          <li>
            <a href="/2018/05/20/Problem_Solving/UVa/UVa-11235-Frequent-values/">UVa 11235 - Frequent values</a>
          </li>
        
          <li>
            <a href="/2018/05/20/Problem_Solving/UVa/UVa-11223-O-dah-dah-dah/">UVa 11223 - O: dah dah dah!</a>
          </li>
        
          <li>
            <a href="/2018/04/23/Problem_Solving/UVa/UVa-394-Mapmaker/">UVa 394 - Mapmaker</a>
          </li>
        
          <li>
            <a href="/2018/04/13/Problem_Solving/UVa/UVa-10901-Ferry-Loading-III/">UVa 10901 - Ferry Loading III</a>
          </li>
        
          <li>
            <a href="/2018/04/11/Problem_Solving/UVa/UVa-1730-Sum-of-MSLCM/">UVa 1730 - Sum of MSLCM</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Chore/">Chore</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/For-Fun/">For Fun</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Problem-Solving/">Problem Solving</a><span class="category-list-count">258</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Problem-Solving/CodeForces/">CodeForces</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Problem-Solving/UVa/">UVa</a><span class="category-list-count">253</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Problem-Solving/ZeroJudge/">ZeroJudge</a><span class="category-list-count">4</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/學習筆記/">學習筆記</a><span class="category-list-count">26</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/學習筆記/ML-Hung-yi-Lee/">ML(Hung-yi Lee)</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/學習筆記/Python/">Python</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/學習筆記/機器學習基石/">機器學習基石</a><span class="category-list-count">11</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/心情隨筆/">心情隨筆</a><span class="category-list-count">3</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a><span class="archive-list-count">40</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">February 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a><span class="archive-list-count">16</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a><span class="archive-list-count">48</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a><span class="archive-list-count">51</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a><span class="archive-list-count">18</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a><span class="archive-list-count">29</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a><span class="archive-list-count">20</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">February 2016</a><span class="archive-list-count">22</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">January 2016</a><span class="archive-list-count">3</span></li></ul>
    </div>
  </div>


  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 NaiveRed<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and Theme by <a href="https://github.com/hexojs/hexo-theme-landscape" target="_blank">landscape</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
</nav>
    
<script>
  var disqus_shortname = 'naivered';
  
  var disqus_url = 'http://naivered.github.io/2017/01/20/Study_Notes/Machine Learning/Machine-Learning-L5-Notes/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>

<!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
</body>
</html>